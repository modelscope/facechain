{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884768f3-e8b2-4c74-812b-538402732df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-14T06:17:14.480479Z",
     "iopub.status.busy": "2023-09-14T06:17:14.480095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-14 14:17:17,627 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.\n",
      "2023-09-14 14:17:17,632 - modelscope - INFO - TensorFlow version 2.13.0 Found.\n",
      "2023-09-14 14:17:17,632 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-09-14 14:17:17,659 - modelscope - INFO - Loading done! Current index file version is 1.9.0, with md5 e024469f80e1732f2cfc5efd837ca7df and a total number of 921 components indexed\n",
      "/opt/conda/lib/python3.8/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "[2023-09-14 14:17:19,063] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2023-09-14 14:17:26.046578: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 14:17:26.088101: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 14:17:26.874976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "app.py:888: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(label='Output', show_label=False).style(columns=3, rows=2, height=600,\n",
      "[['resources/inpaint_template/2.jpg'], ['resources/inpaint_template/1.jpg'], ['resources/inpaint_template/3.jpg'], ['resources/inpaint_template/4.jpg'], ['resources/inpaint_template/5.jpg']]\n",
      "app.py:967: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(\n",
      "Running on local URL:  http://127.0.0.1:7862\n",
      "2023-09-14 14:17:41,913 - modelscope - INFO - Use user-specified model revision: v2.0.9\n",
      "-------user_model:  person1\n",
      "2023-09-14 14:17:45,834 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.\n",
      "2023-09-14 14:17:45,839 - modelscope - INFO - TensorFlow version 2.13.0 Found.\n",
      "2023-09-14 14:17:45,839 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-09-14 14:17:45,867 - modelscope - INFO - Loading done! Current index file version is 1.9.0, with md5 e024469f80e1732f2cfc5efd837ca7df and a total number of 921 components indexed\n",
      "2023-09-14 14:17:46,242 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.\n",
      "2023-09-14 14:17:46,246 - modelscope - INFO - TensorFlow version 2.13.0 Found.\n",
      "2023-09-14 14:17:46,247 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-09-14 14:17:46,272 - modelscope - INFO - Loading done! Current index file version is 1.9.0, with md5 e024469f80e1732f2cfc5efd837ca7df and a total number of 921 components indexed\n",
      "2023-09-14 14:17:46,433 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.\n",
      "2023-09-14 14:17:46,439 - modelscope - INFO - TensorFlow version 2.13.0 Found.\n",
      "2023-09-14 14:17:46,440 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-09-14 14:17:46,445 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.\n",
      "2023-09-14 14:17:46,452 - modelscope - INFO - TensorFlow version 2.13.0 Found.\n",
      "2023-09-14 14:17:46,452 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "/opt/conda/lib/python3.8/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "2023-09-14 14:17:46,481 - modelscope - INFO - Loading done! Current index file version is 1.9.0, with md5 e024469f80e1732f2cfc5efd837ca7df and a total number of 921 components indexed\n",
      "2023-09-14 14:17:46,491 - modelscope - INFO - Loading done! Current index file version is 1.9.0, with md5 e024469f80e1732f2cfc5efd837ca7df and a total number of 921 components indexed\n",
      "2023-09-14 14:17:46,642 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.\n",
      "2023-09-14 14:17:46,646 - modelscope - INFO - TensorFlow version 2.13.0 Found.\n",
      "2023-09-14 14:17:46,647 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-09-14 14:17:46,672 - modelscope - INFO - Loading done! Current index file version is 1.9.0, with md5 e024469f80e1732f2cfc5efd837ca7df and a total number of 921 components indexed\n",
      "/opt/conda/lib/python3.8/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "[2023-09-14 14:17:47,450] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-09-14 14:17:48,008] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-09-14 14:17:48,073] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-09-14 14:17:48,285] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-09-14 14:17:48,397] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2023-09-14 14:17:56.334509: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 14:17:56.335172: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 14:17:56.381640: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 14:17:56.398983: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 14:17:56.812787: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 14:17:56.857638: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 14:17:57.168389: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-14 14:17:57.182520: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-14 14:17:57.679223: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-14 14:17:58.636200: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 14:17:58.698927: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/mnt/workspace/facechain/app.py:888: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(label='Output', show_label=False).style(columns=3, rows=2, height=600,\n",
      "/mnt/workspace/facechain/app.py:888: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(label='Output', show_label=False).style(columns=3, rows=2, height=600,\n",
      "2023-09-14 14:17:59.409051: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 14:17:59.480071: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[['resources/inpaint_template/2.jpg'], ['resources/inpaint_template/1.jpg'], ['resources/inpaint_template/3.jpg'], ['resources/inpaint_template/4.jpg'], ['resources/inpaint_template/5.jpg']]\n",
      "/mnt/workspace/facechain/app.py:967: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(\n",
      "/mnt/workspace/facechain/app.py:888: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(label='Output', show_label=False).style(columns=3, rows=2, height=600,\n",
      "[['resources/inpaint_template/2.jpg'], ['resources/inpaint_template/1.jpg'], ['resources/inpaint_template/3.jpg'], ['resources/inpaint_template/4.jpg'], ['resources/inpaint_template/5.jpg']]\n",
      "/mnt/workspace/facechain/app.py:967: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(\n",
      "2023-09-14 14:17:59.800526: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-14 14:18:00,005 - modelscope - INFO - Use user-specified model revision: v1.0.0\n",
      "[['resources/inpaint_template/2.jpg'], ['resources/inpaint_template/1.jpg'], ['resources/inpaint_template/3.jpg'], ['resources/inpaint_template/4.jpg'], ['resources/inpaint_template/5.jpg']]\n",
      "/mnt/workspace/facechain/app.py:967: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(\n",
      "Loading pipeline components...:   0%|                     | 0/6 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "2023-09-14 14:18:00.564488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Loading pipeline components...:  50%|██████▌      | 3/6 [00:00<00:00,  8.46it/s]/mnt/workspace/facechain/app.py:888: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(label='Output', show_label=False).style(columns=3, rows=2, height=600,\n",
      "Loading pipeline components...:  67%|████████▋    | 4/6 [00:02<00:01,  1.33it/s][['resources/inpaint_template/2.jpg'], ['resources/inpaint_template/1.jpg'], ['resources/inpaint_template/3.jpg'], ['resources/inpaint_template/4.jpg'], ['resources/inpaint_template/5.jpg']]\n",
      "/mnt/workspace/facechain/app.py:967: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(\n",
      "/mnt/workspace/facechain/app.py:888: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(label='Output', show_label=False).style(columns=3, rows=2, height=600,\n",
      "[['resources/inpaint_template/2.jpg'], ['resources/inpaint_template/1.jpg'], ['resources/inpaint_template/3.jpg'], ['resources/inpaint_template/4.jpg'], ['resources/inpaint_template/5.jpg']]\n",
      "/mnt/workspace/facechain/app.py:967: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(\n",
      "Loading pipeline components...: 100%|█████████████| 6/6 [00:03<00:00,  1.71it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "multiplier_style:0.3, multiplier_human:0.95\n",
      "\n",
      "Could not create share link. Missing file: /opt/conda/lib/python3.8/site-packages/gradio/frpc_linux_amd64_v0.2. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_linux_amd64\n",
      "2. Rename the downloaded file to: frpc_linux_amd64_v0.2\n",
      "3. Move the file to this location: /opt/conda/lib/python3.8/site-packages/gradio\n",
      "100%|███████████████████████████████████████████| 40/40 [00:27<00:00,  1.43it/s]\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mconcurrent.futures.process._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/concurrent/futures/process.py\", line 239, in _process_worker\n",
      "    r = call_item.fn(*call_item.args, **call_item.kwargs)\n",
      "  File \"/mnt/workspace/facechain/facechain/inference.py\", line 484, in __call__\n",
      "    gen_results = main_model_inference(self.pose_model_path, self.pose_image, self.use_depth_control,\n",
      "  File \"/mnt/workspace/facechain/facechain/inference.py\", line 368, in main_model_inference\n",
      "    return main_diffusion_inference(pos_prompt, neg_prompt, input_img_dir, base_model_path,\n",
      "  File \"/mnt/workspace/facechain/facechain/inference.py\", line 185, in main_diffusion_inference\n",
      "    images_style = txt2img(pipe, trigger_style + add_prompt_style + pos_prompt, neg_prompt, num_images=10)\n",
      "  File \"/mnt/workspace/facechain/facechain/inference.py\", line 42, in txt2img\n",
      "    images_style = pipe(prompt=pos_prompt, height=512, width=512, guidance_scale=7, negative_prompt=neg_prompt,\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 704, in __call__\n",
      "    image = self.vae.decode(latents / self.vae.config.scaling_factor, return_dict=False)[0]\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/utils/accelerate_utils.py\", line 46, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/models/autoencoder_kl.py\", line 270, in decode\n",
      "    decoded = self._decode(z).sample\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/models/autoencoder_kl.py\", line 257, in _decode\n",
      "    dec = self.decoder(z)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/models/vae.py\", line 271, in forward\n",
      "    sample = up_block(sample, latent_embeds)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/models/unet_2d_blocks.py\", line 2334, in forward\n",
      "    hidden_states = upsampler(hidden_states)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/models/resnet.py\", line 169, in forward\n",
      "    hidden_states = self.conv(hidden_states)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/models/lora.py\", line 96, in forward\n",
      "    return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.25 GiB (GPU 0; 22.20 GiB total capacity; 6.20 GiB already allocated; 653.12 MiB free; 6.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/queueing.py\", line 388, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/route_utils.py\", line 219, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/blocks.py\", line 1437, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/blocks.py\", line 1123, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/utils.py\", line 503, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/utils.py\", line 496, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/utils.py\", line 479, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/utils.py\", line 629, in gen_wrapper\n",
      "    yield from f(*args, **kwargs)\n",
      "  File \"app.py\", line 269, in launch_pipeline\n",
      "    outputs = future.result()\n",
      "  File \"/opt/conda/lib/python3.8/concurrent/futures/_base.py\", line 437, in result\n",
      "    return self.__get_result()\n",
      "  File \"/opt/conda/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
      "    raise self._exception\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.25 GiB (GPU 0; 22.20 GiB total capacity; 6.20 GiB already allocated; 653.12 MiB free; 6.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "2023-09-14 14:19:26,333 - modelscope - INFO - Use user-specified model revision: v2.0.9\n",
      "-------user_model:  person1\n",
      "2023-09-14 14:19:31,163 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.\n",
      "2023-09-14 14:19:31,168 - modelscope - INFO - TensorFlow version 2.13.0 Found.\n",
      "2023-09-14 14:19:31,168 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-09-14 14:19:31,201 - modelscope - INFO - Loading done! Current index file version is 1.9.0, with md5 e024469f80e1732f2cfc5efd837ca7df and a total number of 921 components indexed\n",
      "2023-09-14 14:19:31,236 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.\n",
      "2023-09-14 14:19:31,242 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.\n",
      "2023-09-14 14:19:31,245 - modelscope - INFO - TensorFlow version 2.13.0 Found.\n",
      "2023-09-14 14:19:31,245 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-09-14 14:19:31,249 - modelscope - INFO - TensorFlow version 2.13.0 Found.\n",
      "2023-09-14 14:19:31,249 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-09-14 14:19:31,287 - modelscope - INFO - Loading done! Current index file version is 1.9.0, with md5 e024469f80e1732f2cfc5efd837ca7df and a total number of 921 components indexed\n",
      "2023-09-14 14:19:31,290 - modelscope - INFO - Loading done! Current index file version is 1.9.0, with md5 e024469f80e1732f2cfc5efd837ca7df and a total number of 921 components indexed\n",
      "2023-09-14 14:19:31,440 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.\n",
      "2023-09-14 14:19:31,448 - modelscope - INFO - TensorFlow version 2.13.0 Found.\n",
      "2023-09-14 14:19:31,448 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-09-14 14:19:31,496 - modelscope - INFO - Loading done! Current index file version is 1.9.0, with md5 e024469f80e1732f2cfc5efd837ca7df and a total number of 921 components indexed\n",
      "2023-09-14 14:19:31,557 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.\n",
      "2023-09-14 14:19:31,563 - modelscope - INFO - TensorFlow version 2.13.0 Found.\n",
      "2023-09-14 14:19:31,564 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-09-14 14:19:31,602 - modelscope - INFO - Loading done! Current index file version is 1.9.0, with md5 e024469f80e1732f2cfc5efd837ca7df and a total number of 921 components indexed\n",
      "/opt/conda/lib/python3.8/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "[2023-09-14 14:19:32,894] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-09-14 14:19:33,127] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-09-14 14:19:33,130] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-09-14 14:19:33,298] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-09-14 14:19:33,394] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2023-09-14 14:19:41.877563: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 14:19:41.930404: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 14:19:41.945396: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 14:19:41.973167: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 14:19:42.393391: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 14:19:42.472974: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 14:19:42.768905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-14 14:19:43.079330: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-14 14:19:43.573897: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-14 14:19:44.089337: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 14:19:44.150015: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/mnt/workspace/facechain/app.py:888: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(label='Output', show_label=False).style(columns=3, rows=2, height=600,\n",
      "2023-09-14 14:19:44.837693: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-14 14:19:44.908465: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[['resources/inpaint_template/2.jpg'], ['resources/inpaint_template/1.jpg'], ['resources/inpaint_template/3.jpg'], ['resources/inpaint_template/4.jpg'], ['resources/inpaint_template/5.jpg']]\n",
      "/mnt/workspace/facechain/app.py:967: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(\n",
      "2023-09-14 14:19:45.225765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-09-14 14:19:45,356 - modelscope - INFO - Use user-specified model revision: v1.0.0\n",
      "Loading pipeline components...:   0%|                     | 0/6 [00:00<?, ?it/s]/mnt/workspace/facechain/app.py:888: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(label='Output', show_label=False).style(columns=3, rows=2, height=600,\n",
      "2023-09-14 14:19:45.973612: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/mnt/workspace/facechain/app.py:888: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(label='Output', show_label=False).style(columns=3, rows=2, height=600,\n",
      "Loading pipeline components...:  17%|██▏          | 1/6 [00:00<00:02,  2.19it/s]/opt/conda/lib/python3.8/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "[['resources/inpaint_template/2.jpg'], ['resources/inpaint_template/1.jpg'], ['resources/inpaint_template/3.jpg'], ['resources/inpaint_template/4.jpg'], ['resources/inpaint_template/5.jpg']]\n",
      "/mnt/workspace/facechain/app.py:967: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(\n",
      "Loading pipeline components...:  67%|████████▋    | 4/6 [00:00<00:00,  8.29it/s][['resources/inpaint_template/2.jpg'], ['resources/inpaint_template/1.jpg'], ['resources/inpaint_template/3.jpg'], ['resources/inpaint_template/4.jpg'], ['resources/inpaint_template/5.jpg']]\n",
      "/mnt/workspace/facechain/app.py:967: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(\n",
      "/mnt/workspace/facechain/app.py:888: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(label='Output', show_label=False).style(columns=3, rows=2, height=600,\n",
      "[['resources/inpaint_template/2.jpg'], ['resources/inpaint_template/1.jpg'], ['resources/inpaint_template/3.jpg'], ['resources/inpaint_template/4.jpg'], ['resources/inpaint_template/5.jpg']]\n",
      "/mnt/workspace/facechain/app.py:967: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(\n",
      "/mnt/workspace/facechain/app.py:888: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(label='Output', show_label=False).style(columns=3, rows=2, height=600,\n",
      "[['resources/inpaint_template/2.jpg'], ['resources/inpaint_template/1.jpg'], ['resources/inpaint_template/3.jpg'], ['resources/inpaint_template/4.jpg'], ['resources/inpaint_template/5.jpg']]\n",
      "/mnt/workspace/facechain/app.py:967: GradioDeprecationWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  output_images = gr.Gallery(\n",
      "Loading pipeline components...: 100%|█████████████| 6/6 [00:04<00:00,  1.43it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "multiplier_style:0.3, multiplier_human:0.95\n",
      "100%|███████████████████████████████████████████| 40/40 [00:27<00:00,  1.43it/s]\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0mconcurrent.futures.process._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/concurrent/futures/process.py\", line 239, in _process_worker\n",
      "    r = call_item.fn(*call_item.args, **call_item.kwargs)\n",
      "  File \"/mnt/workspace/facechain/facechain/inference.py\", line 484, in __call__\n",
      "    gen_results = main_model_inference(self.pose_model_path, self.pose_image, self.use_depth_control,\n",
      "  File \"/mnt/workspace/facechain/facechain/inference.py\", line 368, in main_model_inference\n",
      "    return main_diffusion_inference(pos_prompt, neg_prompt, input_img_dir, base_model_path,\n",
      "  File \"/mnt/workspace/facechain/facechain/inference.py\", line 185, in main_diffusion_inference\n",
      "    images_style = txt2img(pipe, trigger_style + add_prompt_style + pos_prompt, neg_prompt, num_images=10)\n",
      "  File \"/mnt/workspace/facechain/facechain/inference.py\", line 42, in txt2img\n",
      "    images_style = pipe(prompt=pos_prompt, height=512, width=512, guidance_scale=7, negative_prompt=neg_prompt,\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py\", line 704, in __call__\n",
      "    image = self.vae.decode(latents / self.vae.config.scaling_factor, return_dict=False)[0]\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/utils/accelerate_utils.py\", line 46, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/models/autoencoder_kl.py\", line 270, in decode\n",
      "    decoded = self._decode(z).sample\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/models/autoencoder_kl.py\", line 257, in _decode\n",
      "    dec = self.decoder(z)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/models/vae.py\", line 271, in forward\n",
      "    sample = up_block(sample, latent_embeds)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/models/unet_2d_blocks.py\", line 2334, in forward\n",
      "    hidden_states = upsampler(hidden_states)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/models/resnet.py\", line 169, in forward\n",
      "    hidden_states = self.conv(hidden_states)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/diffusers/models/lora.py\", line 96, in forward\n",
      "    return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.25 GiB (GPU 0; 22.20 GiB total capacity; 6.20 GiB already allocated; 653.12 MiB free; 6.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/queueing.py\", line 388, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/route_utils.py\", line 219, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/blocks.py\", line 1437, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/blocks.py\", line 1123, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/utils.py\", line 503, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/utils.py\", line 496, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/utils.py\", line 479, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/gradio/utils.py\", line 629, in gen_wrapper\n",
      "    yield from f(*args, **kwargs)\n",
      "  File \"app.py\", line 269, in launch_pipeline\n",
      "    outputs = future.result()\n",
      "  File \"/opt/conda/lib/python3.8/concurrent/futures/_base.py\", line 437, in result\n",
      "    return self.__get_result()\n",
      "  File \"/opt/conda/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
      "    raise self._exception\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.25 GiB (GPU 0; 22.20 GiB total capacity; 6.20 GiB already allocated; 653.12 MiB free; 6.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "!python3 app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf01301-e495-47ec-b4b5-2c67d693f782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
