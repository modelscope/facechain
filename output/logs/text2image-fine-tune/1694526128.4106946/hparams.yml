adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-08
adam_weight_decay: 0.01
allow_tf32: false
cache_dir: null
caption_column: text
center_crop: false
checkpointing_steps: 5000
checkpoints_total_limit: null
dataloader_num_workers: 0
dataset_config_name: null
dataset_name: ./processed_labeled
enable_xformers_memory_efficient_attention: false
gradient_accumulation_steps: 1
gradient_checkpointing: false
hub_model_id: null
hub_token: null
image_column: image
learning_rate: 0.00015
local_rank: -1
logging_dir: logs
lora_alpha: 32
lora_bias: none
lora_dropout: 0.0
lora_r: 4
lora_text_encoder_alpha: 32
lora_text_encoder_bias: none
lora_text_encoder_dropout: 0.0
lora_text_encoder_r: 32
lr_scheduler: cosine
lr_warmup_steps: 0
max_grad_norm: 1.0
max_train_samples: null
max_train_steps: 600
mixed_precision: null
num_train_epochs: 200
num_validation_images: 1
output_dataset_name: ./processed
output_dir: ./output
pretrained_model_name_or_path: ly261666/cv_portrait_model
push_to_hub: false
random_flip: true
report_to: tensorboard
resolution: 512
resume_from_checkpoint: fromfacecommon
revision: v2.0
scale_lr: false
seed: 42
sub_path: film/film
train_batch_size: 1
train_data_dir: null
train_text_encoder: false
use_8bit_adam: false
use_peft: false
validation_epochs: 1
validation_prompt: null
