from __future__ import annotations
import os
import sys
sys.path.append("../../")
from functools import partial

import gradio as gr
from dotenv import load_dotenv
from modelscope_agent.agent import AgentExecutor
from modelscope_agent.llm import LLMFactory
from modelscope_agent.prompt import MSPromptGenerator, PromptGenerator
from modelscope_agent.retrieve import ToolRetrieval
from gradio_chatbot import ChatBot
# from mock_llm import MockLLM
from facechain_tools import StyleSearchTool
import copy

from modelscope.utils.config import Config

PROMPT_START = "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„FacechainAgentï¼Œå¾ˆé«˜å…´ä¸ºä½ æä¾›æœåŠ¡ã€‚é¦–å…ˆï¼Œæˆ‘æƒ³äº†è§£ä½ å¯¹æƒ³è¦åˆ›ä½œçš„å†™çœŸç…§æœ‰ä»€ä¹ˆå¤§æ¦‚çš„æƒ³æ³•ï¼Ÿ"


SYSTEM_PROMPT = """<|system|>: ä½ ç°åœ¨æ‰®æ¼”ä¸€ä¸ªFacechain Agentï¼Œä¸æ–­å’Œç”¨æˆ·æ²Ÿé€šåˆ›ä½œæƒ³æ³•ï¼Œè¯¢é—®ç”¨æˆ·å†™çœŸç…§é£æ ¼ï¼Œæœ€åç”Ÿæˆæœç´¢åˆ°çš„é£æ ¼ç±»å‹è¿”å›ç»™ç”¨æˆ·ã€‚å½“å‰å¯¹è¯å¯ä»¥ä½¿ç”¨çš„æ’ä»¶ä¿¡æ¯å¦‚ä¸‹ï¼Œè¯·è‡ªè¡Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨æ’ä»¶æ¥è§£å†³å½“å‰ç”¨æˆ·é—®é¢˜ã€‚è‹¥éœ€è¦è°ƒç”¨æ’ä»¶ï¼Œåˆ™éœ€è¦å°†æ’ä»¶è°ƒç”¨è¯·æ±‚æŒ‰ç…§jsonæ ¼å¼ç»™å‡ºï¼Œå¿…é¡»åŒ…å«api_nameã€parameterså­—æ®µï¼Œå¹¶åœ¨å…¶å‰åä½¿ç”¨<|startofthink|>å’Œ<|endofthink|>ä½œä¸ºæ ‡å¿—ã€‚ç„¶åä½ éœ€è¦æ ¹æ®æ’ä»¶APIè°ƒç”¨ç»“æœç”Ÿæˆåˆç†çš„ç­”å¤ã€‚
\n<tool_list>\n"""

INSTRUCTION_TEMPLATE = """ã€å¤šè½®å¯¹è¯å†å²ã€‘

Human: ç»™æˆ‘ç”Ÿæˆä¸€ä¸ªå†™çœŸç…§ã€‚

Assistant: å¥½çš„ï¼Œè¯·é—®ä½ æƒ³è¦ä»€ä¹ˆé£æ ¼çš„å†™çœŸç…§ï¼Ÿ

Human: æˆ‘æƒ³è¦èµ›åšæœ‹å…‹é£ã€‚

Assistant: æ˜ç™½äº†ï¼Œæˆ‘å°†ä¸ºä½ æ‰¾åˆ°éœ€è¦çš„é£æ ¼ç±»å‹ã€‚

<|startofthink|>```JSON\n{\n   "api_name": "style_search",\n    "parameters": {\n      "text": "æˆ‘æƒ³è¦èµ›åšæœ‹å…‹é£ã€‚"\n   }\n}\n```<|endofthink|>
æˆ‘ä¸ºä½ æ‰¾åˆ°çš„é£æ ¼ç±»å‹åå­—æ˜¯èµ›åšæœ‹å…‹(Cybernetics punk)ï¼Œè¯¥é£æ ¼æ–‡ä»¶ä½ç½®åœ¨/content/modelscope-agent/demo/story_agent/style/Cybernetics_punk.jsonã€‚

ã€è§’è‰²æ‰®æ¼”è¦æ±‚ã€‘
ä¸Šé¢å¤šè½®è§’è‰²å¯¹è¯æ˜¯æä¾›çš„åˆ›ä½œä¸€ä¸ªå†™çœŸç…§é£æ ¼è¦å’Œç”¨æˆ·æ²Ÿé€šçš„æ ·ä¾‹ï¼Œè¯·æŒ‰ç…§ä¸Šè¿°çš„è¯¢é—®æ­¥éª¤æ¥å¼•å¯¼ç”¨æˆ·å®Œæˆé£æ ¼çš„ç”Ÿæˆï¼Œæ¯æ¬¡åªå›å¤å¯¹åº”çš„å†…å®¹ï¼Œä¸è¦ç”Ÿæˆå¤šè½®å¯¹è¯ã€‚è®°ä½åªå›å¤ç”¨æˆ·å½“å‰çš„æé—®ï¼Œä¸è¦ç”Ÿæˆå¤šè½®å¯¹è¯ï¼Œå›å¤ä¸è¦åŒ…å«<|user|>åé¢çš„å†…å®¹ã€‚

"""

KEY_TEMPLATE = """ï¼ˆæ³¨æ„ï¼šè¯·å‚ç…§ä¸Šè¿°çš„å¤šè½®å¯¹è¯å†å²æµç¨‹ï¼Œä½†ä¸è¦ç”Ÿæˆå¤šè½®å¯¹è¯ï¼Œå›å¤ä¸è¦åŒ…å«<|user|>çš„å†…å®¹ã€‚ï¼‰"""
#KEY_TEMPLATE = ""

MAX_SCENE = 4

load_dotenv('../../config/.env', override=True)

os.environ['TOOL_CONFIG_FILE'] = '../../config/cfg_tool_template.json'
os.environ['MODEL_CONFIG_FILE'] = '../../config/cfg_model_template.json'
os.environ['OUTPUT_FILE_DIRECTORY'] = './tmp'
os.environ['MODELSCOPE_API_TOKEN'] = 'c70a097b-50bd-42da-9d45-23bed2121eab'
os.environ['DASHSCOPE_API_KEY'] = 'uwjIui5vzfMXRGfWzdU5hkPdE0FJTFFW95425EAEDCCB11ED9809620D7200B5B8'
os.environ['OPENAI_API_KEY'] = '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'

IMAGE_TEMPLATE_PATH = [
    'img_example/1.png',
    'img_example/2.png',
]


with open(
        os.path.join(os.path.dirname(__file__), 'main.css'), "r",
        encoding="utf-8") as f:
    MAIN_CSS_CODE = f.read()

with gr.Blocks(css=MAIN_CSS_CODE, theme=gr.themes.Soft()) as demo:

    max_scene = MAX_SCENE

    with gr.Row():
        gr.HTML(
            """<h1 align="left" style="min-width:200px; margin-top:0;">Facechain Agent</h1>"""
        )
        status_display = gr.HTML(
            "", elem_id="status_display", visible=False, show_label=False)

    with gr.Row(elem_id="container_row").style(equal_height=True):

        with gr.Column(scale=6):
            
            #story_content = gr.Textbox(label='æ•…äº‹æƒ…èŠ‚', lines=4, interactive=False)
            # story_content = ""
            output_image = [None] * max_scene
            output_text = [None] * max_scene

            for i in range(0, max_scene, 2):
                with gr.Row():
                    with gr.Column():
                        output_image[i] = gr.Image(
                            label=f'ç¤ºä¾‹å›¾ç‰‡{i + 1}',
                            interactive=False,
                            height=200,
                            visible=False,
                            show_progress=False)
                        output_text[i] = gr.Textbox(
                            label=f'æ•…äº‹æƒ…èŠ‚{i + 1}', lines=2, interactive=False, visible=False, show_progress=False)
                    with gr.Column():
                        output_image[i + 1] = gr.Image(
                            label=f'ç¤ºä¾‹å›¾ç‰‡{i +2}', interactive=False, height=200, visible=False, show_progress=False)
                        output_text[i + 1] = gr.Textbox(
                            label=f'æ•…äº‹æƒ…èŠ‚{i + 2}', lines=2, interactive=False, visible=False, show_progress=False)

        with gr.Column(min_width=470, scale=6, elem_id='settings'):

            chatbot = ChatBot(
                elem_id="chatbot",
                elem_classes=["markdown-body"],
                show_label=False,
                height=600)
            with gr.Row(elem_id="chat-bottom-container"):
                with gr.Column(min_width=70, scale=1):
                    clear_session_button = gr.Button(
                        "æ¸…é™¤", elem_id='clear_session_button', default_value=True)
                with gr.Column(scale=12):
                    user_input = gr.Textbox(
                        show_label=False,
                        placeholder="ä¸€èµ·æ¥è‡ªç”±ç”Ÿæˆå†™çœŸç…§å§ï½",
                        elem_id="chat-input").style(container=False)
                with gr.Column(min_width=70, scale=1):
                    submitBtn = gr.Button("å‘é€", variant="primary")
                with gr.Column(min_width=110, scale=1):
                    regenerate_button = gr.Button(
                        "é‡æ–°ç”Ÿæˆ", elem_id='regenerate_button')

            # gr.Examples(
            #     examples=['ç»™æˆ‘ç”Ÿæˆä¸€ä¸ªè¶…çº§å‘æ—¥è‘µåˆºçŒ¬çš„æ•…äº‹', 'æ¯ä¸ªæ®µè½æ•…äº‹é‡Œé¢éƒ½åŠ ä¸Šè¶…çº§å‘æ—¥è‘µåˆºçŒ¬', 'å¯ä»¥çš„ï¼Œæ•…äº‹ç”Ÿæˆçš„ä¸é”™ï¼Œæˆ‘å¾ˆå–œæ¬¢ï¼', 'å¡é€šç”»é£æ ¼'],
            #     inputs=[user_input],
            #     examples_per_page=20,
            #     label="ç¤ºä¾‹",
            #     elem_id="chat-examples")

            # steps = gr.Slider(
            #     minimum=1,
            #     maximum=max_scene,
            #     value=1,
            #     step=1,
            #     label='ç”Ÿæˆç»˜æœ¬çš„æ•°ç›®',
            #     interactive=True)
            #steps = 4

    # ----------agent å¯¹è±¡åˆå§‹åŒ–--------------------

    tool_cfg_file = os.getenv('TOOL_CONFIG_FILE')
    model_cfg_file = os.getenv('MODEL_CONFIG_FILE')

    tool_cfg = Config.from_file(tool_cfg_file)
    model_cfg = Config.from_file(model_cfg_file)

    model_name = 'openai'
    llm = LLMFactory.build_llm(model_name, model_cfg)
    #llm = MockLLM()

    prompt_generator = MSPromptGenerator(
        system_template=SYSTEM_PROMPT,
        instruction_template=INSTRUCTION_TEMPLATE)

    # model_cfg = {
    #     'modelscope-agent-qwen-7b': {
    #         'model_id': 'damo/MSAgent-Qwen-7B',
    #         'model_revision': 'v1.0.2',
    #         'use_raw_generation_config': True,
    #         'custom_chat': True
    #     }
    # }


    # tools 
    style_path="facechain/styles/leosamsMoonfilm_filmGrain20"
    # print_story_tool = PrintStoryTool()
    # show_img_example_tool = ShowExampleTool(IMAGE_TEMPLATE_PATH)
    # image_generation_tool = ImageGenerationTool(output_image, output_text, tool_cfg)
    style_search_tool=StyleSearchTool(style_path)
    additional_tool_list = {
        # print_story_tool.name: print_story_tool,
        # show_img_example_tool.name: show_img_example_tool,
        # image_generation_tool.name: image_generation_tool,
        style_search_tool.name: style_search_tool
    }

    agent = AgentExecutor(
        llm,
        tool_cfg,
        prompt_generator=prompt_generator,
        tool_retrieval=False,
        additional_tool_list=additional_tool_list)

    agent.set_available_tools(additional_tool_list.keys())

    def story_agent(*inputs):

        global agent
        user_input = inputs[0] 
        chatbot = inputs[1]
        chatbot.append((user_input, None))
        #chatbotd(user_input)
        yield chatbot
    
        response = ''
        
        for frame in agent.stream_run(user_input+KEY_TEMPLATE, remote=True):
            is_final = frame.get("frame_is_final")
            llm_result = frame.get("llm_text", "")
            exec_result = frame.get('exec_result', '') 
            #print(frame)
            llm_result = llm_result.split("<|user|>")[0].strip()
            if len(exec_result) != 0:
                
                frame_text = " "
            else:
                # action_exec_result
                frame_text = llm_result
            response = f'{response}\n{frame_text}'
        print("user_input: ",user_input)
        print("response: ",response)
        chatbot[-1] = (user_input, response)
        yield chatbot
    
        
        # chatbot[-1] = (user_input, response)
        # yield chatbot
    
    # ---------- äº‹ä»¶ ---------------------

    stream_predict_input = [user_input, chatbot]
    stream_predict_output = [chatbot]

    clean_outputs_start = ['', gr.update(value=[(None, PROMPT_START)])] + [None] * max_scene + [''] * max_scene
    clean_outputs = ['', gr.update(value=[])] + [None] * max_scene + [''] * max_scene
    clean_outputs_target = [user_input, chatbot, *output_image, *output_text]
    user_input.submit(
        story_agent,
        inputs=stream_predict_input,
        outputs=stream_predict_output,
        show_progress=True)
    user_input.submit(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)

    submitBtn.click(
        story_agent,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)
    submitBtn.click(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)

    regenerate_button.click(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)
    regenerate_button.click(
        story_agent,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)

    def clear_session():
        agent.reset()

    clear_session_button.click(fn=clear_session, inputs=[], outputs=[])
    clear_session_button.click(
        fn=lambda: clean_outputs_start, inputs=[], outputs=clean_outputs_target)
  
    # chatbot.append((None, PROMPT_START))
    demo.title = "Facechian Agent ğŸ"
    demo.queue(concurrency_count=10, status_update_rate='auto', api_open=False)
    demo.launch(show_api=False, share=True)
