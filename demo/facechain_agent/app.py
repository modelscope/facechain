from __future__ import annotations
import os
#å®‰è£…åå¯ä»¥æ³¨é‡Šæˆ–è€…åˆ é™¤
os.system('pip install modelscope_agent-0.1.0-py3-none-any.whl')#æ ¹æ®modelscope agent é¡¹ç›®ç”Ÿæˆ.whlåŒ…
os.system('pip install gradio==3.29.0')
import sys
sys.path.append("../../")
from functools import partial
import json
import shutil
import slugify
import glob
from torch import multiprocessing
import PIL.Image
import gradio as gr
from dotenv import load_dotenv
from modelscope_agent.agent import AgentExecutor
from modelscope_agent.llm import LLMFactory
from modelscope_agent.prompt import MSPromptGenerator, PromptGenerator
from modelscope_agent.retrieve import ToolRetrieval
from gradio_chatbot import ChatBot
#from mock_llm import MockLLM
from help_tool import StyleSearchTool,FaceChainFineTuneTool,FaceChainInferenceTool
import copy
from facechain.train_text_to_image_lora import prepare_dataset
from modelscope.utils.config import Config
import uuid


# ç”Ÿæˆéšæœºçš„ UUIDï¼ˆå’Œuuid=â€˜qw'ä¸ä¸€æ ·ï¼‰
random_uuid = uuid.uuid4()

# å°† UUID è½¬æ¢ä¸ºå­—ç¬¦ä¸²
uuid_str = str(random_uuid)
image_num = 3
PROMPT_START = "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„FacechainAgentï¼Œå¾ˆé«˜å…´ä¸ºä½ æä¾›æœåŠ¡ã€‚é¦–å…ˆï¼Œæˆ‘æƒ³äº†è§£ä½ å¯¹æƒ³è¦åˆ›ä½œçš„å†™çœŸç…§æœ‰ä»€ä¹ˆå¤§æ¦‚çš„æƒ³æ³•ï¼Ÿ"

SYSTEM_PROMPT = """<|system|>: ä½ ç°åœ¨æ‰®æ¼”ä¸€ä¸ªFacechain Agentï¼Œä¸æ–­å’Œç”¨æˆ·æ²Ÿé€šåˆ›ä½œæƒ³æ³•ï¼Œè¯¢é—®ç”¨æˆ·å†™çœŸç…§é£æ ¼ï¼Œæœ€åç”Ÿæˆæœç´¢åˆ°çš„é£æ ¼ç±»å‹è¿”å›ç»™ç”¨æˆ·ã€‚å½“å‰å¯¹è¯å¯ä»¥ä½¿ç”¨çš„æ’ä»¶ä¿¡æ¯å¦‚ä¸‹ï¼Œè¯·è‡ªè¡Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨æ’ä»¶æ¥è§£å†³å½“å‰ç”¨æˆ·é—®é¢˜ã€‚è‹¥éœ€è¦è°ƒç”¨æ’ä»¶ï¼Œåˆ™éœ€è¦å°†æ’ä»¶è°ƒç”¨è¯·æ±‚æŒ‰ç…§jsonæ ¼å¼ç»™å‡ºï¼Œå¿…é¡»åŒ…å«api_nameã€parameterså­—æ®µï¼Œå¹¶åœ¨å…¶å‰åä½¿ç”¨<|startofthink|>å’Œ<|endofthink|>ä½œä¸ºæ ‡å¿—ã€‚ç„¶åä½ éœ€è¦æ ¹æ®æ’ä»¶APIè°ƒç”¨ç»“æœç”Ÿæˆåˆç†çš„ç­”å¤ã€‚
\n<tool_list>\n"""

INSTRUCTION_TEMPLATE = """ã€å¤šè½®å¯¹è¯å†å²ã€‘

<|user|>: ç»™æˆ‘ç”Ÿæˆä¸€ä¸ªå†™çœŸç…§ã€‚

<|assistant|>: å¥½çš„ï¼Œè¯·é—®æ‚¨æƒ³è¦ä»€ä¹ˆé£æ ¼çš„å†™çœŸç…§ï¼Ÿ

<|user|>: æˆ‘æƒ³è¦èµ›åšæœ‹å…‹é£ã€‚

<|assistant|>: å¥½çš„ï¼Œæˆ‘å°†ä¸ºæ‚¨æ‰¾åˆ°è¿™ä¸ªé£æ ¼ç±»å‹ã€‚
æ­£åœ¨æœç´¢é£æ ¼ç±»å‹ï¼š
<|startofthink|>```JSON\n{\n   "api_name": "style_search_tool",\n    "parameters": {\n      "text": "æˆ‘æƒ³è¦èµ›åšæœ‹å…‹é£ã€‚"\n   }\n}\n```<|endofthink|>

ç°åœ¨æˆ‘éœ€è¦ä½ æä¾›1-3å¼ ç…§ç‰‡ï¼Œè¯·ç‚¹å‡»å›¾ç‰‡ä¸Šä¼ æŒ‰é’®ä¸Šä¼ ä½ çš„ç…§ç‰‡ã€‚ä¸Šä¼ å®Œæ¯•ååœ¨å¯¹è¯æ¡†é‡Œå‘Šè¯‰æˆ‘ä½ å·²ç»ä¸Šä¼ å¥½ç…§ç‰‡äº†ã€‚

<|user|>: æˆ‘çš„ç…§ç‰‡ä¸Šä¼ å¥½äº†ã€‚

<|assistant|>: æ”¶åˆ°ï¼Œæˆ‘éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´è®­ç»ƒä½ ä¸Šä¼ çš„ç…§ç‰‡ï¼Œç„¶åå†ç”Ÿæˆæ‚¨çš„èµ›åšæœ‹å…‹é£æ ¼å†™çœŸç…§ã€‚

æ­£åœ¨è®­ç»ƒäººç‰©loraä¸­ï¼š
<|startofthink|>```JSON\n{\n   "api_name": "facechain_finetune_tool",\n    "parameters": {}\n}\n```<|endofthink|>

äººç‰©loraè®­ç»ƒå®Œæˆã€‚æ­£åœ¨ç”Ÿæˆä½ é€‰æ‹©çš„èµ›åšæœ‹å…‹é£æ ¼å†™çœŸç…§ä¸­ï¼š
<|startofthink|>```JSON\n{\n   "api_name": "facechain_inference_tool",\n    "parameters": {\n   "matched_style_file_path": "../../styles/leosamsMoonfilm_filmGrain20/Cybernetics_punk.json"\n  }\n}\n```<|endofthink|>

å†™çœŸç…§å·²ç»ç”Ÿæˆå®Œæ¯•ï¼Œå¦‚æœå–œæ¬¢èµ¶ç´§ä¸‹è½½æ‰“å°å§ï¼ä½ å¯ä»¥ç»§ç»­ç”Ÿæˆè¿™ç±»é£æ ¼çš„ç…§ç‰‡æˆ–è€…è·Ÿæˆ‘è¯´æ¢ä¸€ä¸ªé£æ ¼

<|user|>: å†æ¢ä¸€ä¸ªå¤é£é£æ ¼å§

<|assistant|>: å¥½çš„ï¼Œæˆ‘å°†é¦–å…ˆæœç´¢ç›¸å…³é£æ ¼ï¼Œç„¶åå†ä¸ºæ‚¨ç”Ÿæˆå¤é£é£æ ¼çš„å†™çœŸ

æ­£åœ¨æœç´¢é£æ ¼ç±»å‹ï¼š
<|startofthink|>```JSON\n{\n   "api_name": "style_search_tool",\n    "parameters": {\n      "text": "å†æ¢ä¸€ä¸ªå¤é£é£æ ¼å§"\n   }\n}\n```<|endofthink|>

æ­£åœ¨ç”Ÿæˆå¤é£é£æ ¼å†™çœŸç…§ä¸­ï¼š
<|startofthink|>```JSON\n{\n   "api_name": "facechain_inference_tool",\n    "parameters": {\n   "matched_style_file_path": "../../styles/leosamsMoonfilm_filmGrain20/Old_style.json"\n  }\n}\n```<|endofthink|>

å¤é£å†™çœŸå·²ç»ç”Ÿæˆå®Œæ¯•ï¼Œèµ¶ç´§ä¸‹è½½æ‰“å°å§ï¼ä½ è¿˜å¯ä»¥ç»§ç»­ç”Ÿæˆè¿™ç±»é£æ ¼çš„ç…§ç‰‡æˆ–è€…è·Ÿæˆ‘è¯´æ¢ä¸€ä¸ªé£æ ¼
ã€è§’è‰²æ‰®æ¼”è¦æ±‚ã€‘
ä¸Šé¢å¤šè½®è§’è‰²å¯¹è¯æ˜¯æä¾›çš„åˆ›ä½œä¸€ä¸ªå†™çœŸç…§é£æ ¼è¦å’Œç”¨æˆ·æ²Ÿé€šçš„æ ·ä¾‹ï¼Œè¯·æŒ‰ç…§ä¸Šè¿°çš„è¯¢é—®æ­¥éª¤æ¥å¼•å¯¼ç”¨æˆ·å®Œæˆé£æ ¼çš„ç”Ÿæˆï¼Œæ¯æ¬¡åªå›å¤å¯¹åº”çš„å†…å®¹ï¼Œä¸è¦ç”Ÿæˆå¤šè½®å¯¹è¯ã€‚è®°ä½åªå›å¤ç”¨æˆ·å½“å‰çš„æé—®ï¼Œä¸è¦ç”Ÿæˆå¤šè½®å¯¹è¯ï¼Œå›å¤ä¸è¦åŒ…å«<|user|>åé¢çš„å†…å®¹ã€‚

"""

# INSTRUCTION_TEMPLATE = """ã€å¤šè½®å¯¹è¯å†å²ã€‘

# <|user|>: ç»™æˆ‘ç”Ÿæˆä¸€ä¸ªå†™çœŸç…§ã€‚

# <|assistant|>: å¥½çš„ï¼Œè¯·é—®ä½ æƒ³è¦ä»€ä¹ˆé£æ ¼çš„å†™çœŸç…§ï¼Ÿ

# <|user|>: æˆ‘æƒ³è¦èµ›åšæœ‹å…‹é£ã€‚

# <|assistant|>: å¥½çš„ï¼Œæˆ‘å°†ä¸ºä½ æ‰¾åˆ°è¿™ä¸ªé£æ ¼ç±»å‹ã€‚
# æ­£åœ¨æœç´¢é£æ ¼ç±»å‹ï¼š

# <|startofthink|>JSON\n{\n   "api_name": "style_search_tool",\n    "parameters": {\n      "text": "æˆ‘æƒ³è¦èµ›åšæœ‹å…‹é£ã€‚"\n   }\n}\n<|endofthink|>

# <|startofexec|>```JSON\n{"result": {"name": "style_search_tool", "value": "èµ›åšæœ‹å…‹(Cybernetics punk)", file_path: "../../styles/leosamsMoonfilm_filmGrain20/Cybernetics_punk.json"}}\n```<|endofexec|>

# æˆ‘ä¸ºä½ æ‰¾åˆ°çš„é£æ ¼ç±»å‹åå­—æ˜¯èµ›åšæœ‹å…‹(Cybernetics punk)ã€‚ç°åœ¨æˆ‘éœ€è¦ä½ æä¾›1-3å¼ ç…§ç‰‡ï¼Œè¯·ç‚¹å‡»ä¸Šä¼ ç…§ç‰‡æŒ‰é’®ä¸Šä¼ ä½ çš„ç…§ç‰‡ã€‚
# ä¸Šä¼ å®Œæ¯•ååœ¨å¯¹è¯æ¡†é‡Œå‘Šè¯‰æˆ‘ä½ å·²ç»ä¸Šä¼ å¥½ç…§ç‰‡äº†ã€‚

# <|user|>: æˆ‘çš„ç…§ç‰‡ä¸Šä¼ å¥½äº†ã€‚

# <|assistant|>: æ”¶åˆ°ï¼Œæˆ‘éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´è®­ç»ƒä½ ä¸Šä¼ çš„ç…§ç‰‡ã€‚
# æ­£åœ¨è®­ç»ƒäººç‰©loraä¸­ï¼š
# <|startofthink|>```JSON\n{\n   "api_name": "facechain_finetune_tool",\n    "parameters": {}\n}\n```<|endofthink|>

# äººç‰©loraè®­ç»ƒå®Œæˆã€‚ä½ è¦ä½¿ç”¨ä½ ä¹‹å‰é€‰æ‹©çš„èµ›åšæœ‹å…‹(Cybernetics punk)é£æ ¼ç”Ÿæˆå†™çœŸç…§å—ï¼Œè¿˜æ˜¯ä½ è¦æ›´æ¢é£æ ¼ï¼Ÿ

# <|user|>: ä¸æ¢ï¼Œå°±ç”¨è¿™ä¸ªé£æ ¼ã€‚

# <|assistant|>: å¥½çš„ï¼Œæˆ‘å°†ä¸ºä½ ç”Ÿæˆèµ›åšæœ‹å…‹(Cybernetics punk)é£æ ¼çš„å†™çœŸç…§ã€‚è¿™å°†éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚
# æ­£åœ¨ç”Ÿæˆå†™çœŸç…§ä¸­ï¼š
# <|startofthink|>```JSON\n{\n   "api_name": "facechain_inference_tool",\n    "parameters": {\n   "matched_style_file_path": "/home/wsco/wyj2/facechain-agent/styles/leosamsMoonfilm_filmGrain20/Cybernetics_punk.json"\n  }\n}\n```<|endofthink|>

# å†™çœŸç…§å·²ç»ç”Ÿæˆå®Œæ¯•ï¼Œå¦‚æœå–œæ¬¢èµ¶ç´§ä¸‹è½½æ‰“å°å§ï¼

# <|user|>: æˆ‘ç°åœ¨æƒ³æ¢ä¸ªé£æ ¼ï¼Œæˆ‘æƒ³è¦å·¥ä½œé£ã€‚

# <|assistant|>:å¥½çš„ï¼Œæˆ‘å°†æ›´æ–°ä½ æƒ³è¦çš„é£æ ¼ç±»å‹ã€‚
# æ­£åœ¨æœç´¢é£æ ¼ç±»å‹ï¼š<|startofthink|>```JSON\n{\n   "api_name": "style_search_tool",\n    "parameters": {\n      "text": "æˆ‘ç°åœ¨æƒ³æ¢ä¸ªé£æ ¼ï¼Œæˆ‘æƒ³è¦å·¥ä½œé£ã€‚"\n   }\n}\n```<|endofthink|>

# æˆ‘ä¸ºä½ æ‰¾åˆ°çš„é£æ ¼ç±»å‹åå­—æ˜¯å·¥ä½œæœ(Working suit)ã€‚
# æˆ‘ç°åœ¨å°†ç”¨å‰é¢ä½ ä¸Šä¼ çš„ç…§ç‰‡å’Œæ–°é€‰æ‹©çš„é£æ ¼ç”Ÿæˆå†™çœŸç…§ã€‚
# æ­£åœ¨ç”Ÿæˆå†™çœŸç…§ä¸­ï¼š
# <|startofthink|>```JSON\n{\n   "api_name": "facechain_inference_tool",\n    "parameters": {\n   "matched_style_file_path": "/home/wsco/wyj2/facechain-agent/styles/leosamsMoonfilm_filmGrain20/Working_suit.json"\n  }\n}\n```<|endofthink|>

# å†™çœŸç…§å·²ç»ç”Ÿæˆå®Œæ¯•ï¼Œå¦‚æœå–œæ¬¢èµ¶ç´§ä¸‹è½½æ‰“å°å§ï¼
# ã€è§’è‰²æ‰®æ¼”è¦æ±‚ã€‘
# ä¸Šé¢å¤šè½®è§’è‰²å¯¹è¯æ˜¯æä¾›çš„åˆ›ä½œä¸€ä¸ªå†™çœŸç…§é£æ ¼è¦å’Œç”¨æˆ·æ²Ÿé€šçš„æ ·ä¾‹ï¼Œè¯·æŒ‰ç…§ä¸Šè¿°çš„è¯¢é—®æ­¥éª¤æ¥å¼•å¯¼ç”¨æˆ·å®Œæˆé£æ ¼çš„ç”Ÿæˆï¼Œæ¯æ¬¡åªå›å¤å¯¹åº”çš„å†…å®¹ï¼Œä¸è¦ç”Ÿæˆå¤šè½®å¯¹è¯ã€‚è®°ä½åªå›å¤ç”¨æˆ·å½“å‰çš„æé—®ï¼Œä¸è¦ç”Ÿæˆå¤šè½®å¯¹è¯ï¼Œå›å¤ä¸è¦åŒ…å«<|user|>åé¢çš„å†…å®¹ã€‚

# """

KEY_TEMPLATE = """ï¼ˆæ³¨æ„ï¼šè¯·å‚ç…§ä¸Šè¿°çš„å¤šè½®å¯¹è¯å†å²æµç¨‹ï¼Œä½†ä¸è¦ç”Ÿæˆå¤šè½®å¯¹è¯ï¼Œå›å¤ä¸è¦åŒ…å«<|user|>çš„å†…å®¹ã€‚ï¼‰"""


load_dotenv('../config/.env', override=True)
os.environ['TOOL_CONFIG_FILE'] = '../config/cfg_tool_template.json'
os.environ['MODEL_CONFIG_FILE'] = '../config/cfg_model_template.json'
os.environ['OUTPUT_FILE_DIRECTORY'] = './tmp'
#write your key here or write in ../config/.env
os.environ['MODELSCOPE_API_TOKEN'] = 'xxx'
os.environ['DASHSCOPE_API_KEY'] = 'xxx'
os.environ['OPENAI_API_KEY'] = 'xxx'

style_paths=["../../styles/leosamsMoonfilm_filmGrain20","../../styles/MajicmixRealistic_v6"]
styles=[]
for folder_path in style_paths:
    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)
        with open(file_path, "r") as f:
            data = json.load(f)
            styles.append(data)

with open(
        os.path.join(os.path.dirname(__file__), 'main.css'), "r",
        encoding="utf-8") as f:
    MAIN_CSS_CODE = f.read()

def add_file(history,files,task_history,output_model_name):
        history = history+[((file.name,), None) for file in files]
        task_history = task_history + [((file.name,), None) for file in files]
        file_paths = []
        filtered_list = []
        print(history)
        file_paths =[item[0][0] for item in history]
        print("#####",file_paths)
        filtered_list = [item for item in file_paths if '.jpg' in item or '.png' in item]
        print("#####",filtered_list)
        uuid = 'qw'
        #shutil.rmtree(f"./{uuid}", ignore_errors=True)
        base_model_path = 'ly261666/cv_portrait_model'
        revision = 'v2.0'
        sub_path = "film/film"
        output_model_name = uuid_str
        output_model_name = slugify.slugify(output_model_name)
    
        instance_data_dir = os.path.join('./', uuid, 'training_data', base_model_path, output_model_name)
        shutil.rmtree(instance_data_dir, ignore_errors=True)   
        prepare_dataset(filtered_list, instance_data_dir)
        return history,task_history
def reset_user_input():
        return gr.update(value="")

with gr.Blocks(css=MAIN_CSS_CODE, theme=gr.themes.Soft()) as demo:
   
    with gr.Row():
        gr.HTML(
            """<h1 align="left" style="min-width:200px; margin-top:0;">Facechain Agent</h1>"""
        )
        status_display = gr.HTML(
            "", elem_id="status_display", visible=False, show_label=False)


    with gr.Row():
        gr.Markdown(""" ğŸŒˆ ğŸŒˆ ğŸŒˆ
                    
                    ## ä½ å¥½ï¼Œæˆ‘æ˜¯FaceChain Agentï¼Œå¯ä»¥å¸®ä½ ç”Ÿæˆå†™çœŸç…§ç‰‡ã€‚
                    
                    ## å³å›¾æ˜¯å„ç±»é£æ ¼çš„å±•ç¤ºå›¾ï¼Œä½ å¯ä»¥åœ¨è¿™å…ˆæŒ‘é€‰ä½ å–œæ¬¢çš„é£æ ¼ã€‚
                    
                    ## ç„¶ååœ¨ä¸‹æ–¹çš„èŠå¤©æ¡†é‡Œä¸æˆ‘äº¤æµå§ï¼Œä¸€èµ·æ¥ç”Ÿæˆç¾å¦™çš„å†™çœŸç…§ï¼
                    
                    """)
        gallery = gr.Gallery(value=[(os.path.join("../../",item["img"]), item["name"]) for item in styles],
                                        elem_id='gallery',
                                        ).style(object_fit='contain',preview=True,columns=6)
    with gr.Row(elem_id="container_row").style(equal_height=True):
        with gr.Column(scale=8, elem_classes=["chatInterface", "chatDialog", "chatContent"]):
            with gr.Row(elem_id='chat-container'):
                chatbot = ChatBot(
                    elem_id="chatbot",
                    elem_classes=["markdown-body"],
                    show_label=True,
                    )
                task_history = gr.State([])
            with gr.Row(elem_id="chat-bottom-container"):
                with gr.Column(min_width=70, scale=1):
                    clear_session_button = gr.Button(
                        "æ¸…é™¤", elem_id='clear_session_button', default_value=True)
                with gr.Column(scale=12):
                    user_input = gr.Textbox(
                        show_label=False,
                        placeholder="ä¸€èµ·æ¥è‡ªç”±ç”Ÿæˆå†™çœŸç…§å§ï½",
                        elem_id="chat-input").style(container=False)
                with gr.Column(min_width=70, scale=1):
                    submitBtn = gr.Button("å‘é€", variant="primary")
                with gr.Column(min_width=110, scale=1):
                    upload_button = gr.UploadButton("ä¸Šä¼ ç…§ç‰‡", file_types=["image"],file_count="multiple")
                with gr.Column(min_width=110, scale=1):
                    regenerate_button = gr.Button(
                        "é‡æ–°ç”Ÿæˆ", elem_id='regenerate_button')
                    
            gr.Examples(
            examples=['æˆ‘æƒ³è¦å†™çœŸç…§','æˆ‘æƒ³è¦å‡¤å† éœå¸”é£','æˆ‘çš„ç…§ç‰‡ä¸Šä¼ å¥½äº†','ä¸æ¢ï¼Œå°±ç”¨è¿™ä¸ªé£æ ¼','æˆ‘ç°åœ¨æƒ³æ¢ä¸ªé£æ ¼ï¼Œæˆ‘æƒ³è¦å·¥ä½œé£'],
            inputs=[user_input],
            label="ç¤ºä¾‹",
            elem_id="chat-examples")


    # ----------agent å¯¹è±¡åˆå§‹åŒ–--------------------

    tool_cfg_file = os.getenv('TOOL_CONFIG_FILE')
    model_cfg_file = os.getenv('MODEL_CONFIG_FILE')

    tool_cfg = Config.from_file(tool_cfg_file)
    model_cfg = Config.from_file(model_cfg_file)

    model_name = 'openai'
    #model_name = 'modelscope-agent-7b'
    llm = LLMFactory.build_llm(model_name, model_cfg)
    #llm = MockLLM()

    prompt_generator = MSPromptGenerator(
        system_template=SYSTEM_PROMPT,
        instruction_template=INSTRUCTION_TEMPLATE)


    # tools 

    style_search_tool=StyleSearchTool(style_paths)
    facechain_finetune_tool=FaceChainFineTuneTool(uuid_str)#åˆå§‹åŒ–lora_name,åŒºåˆ†ä¸åŒç”¨æˆ·
    facechain_inference_tool=FaceChainInferenceTool(uuid_str)
    additional_tool_list = {
        style_search_tool.name: style_search_tool,
        facechain_finetune_tool.name: facechain_finetune_tool,
        facechain_inference_tool.name: facechain_inference_tool
    }

    agent = AgentExecutor(
        llm,
        tool_cfg,
        prompt_generator=prompt_generator,
        tool_retrieval=False,
        additional_tool_list=additional_tool_list,
        #knowledge_retrieval=knowledge_retrieval
        )

    agent.set_available_tools(additional_tool_list.keys())

    def story_agent(*inputs):

        global agent
        user_input = inputs[0] 
        chatbot = inputs[1]
        task_history = inputs[2]
        output_component = list(inputs[3:])
        def reset_component():
            for i in range(image_num):
                output_component[i+1] = gr.Image.update(visible=False)
        
        chatbot.append((user_input, None))
        task_history.append((user_input, None))
        #chatbotd(user_input)
        yield chatbot,*output_component,task_history
        
        def update_component(exec_result,history,task_history):
            exec_result = exec_result['result']
            name = exec_result.pop('name')
            if name == 'facechain_inference_tool':
                #print("#############-------------")
                single_path = exec_result['single_path']
                image_files = glob.glob(os.path.join(single_path, '*.jpg'))
                image_files += glob.glob(os.path.join(single_path, '*.png'))
                # output_component[0] = gr.Image.update(image_files[0])
                # output_component[1] = gr.Image.update(image_files[1])
                # output_component[2] = gr.Image.update(image_files[2])
                history = [(None,(file,)) for file in image_files] 
                task_history  = task_history + [(None,(file,)) for file in image_files] 
            else:
                history = [] 
                task_history  = task_history
            return history,task_history       
        response = ''        
        for frame in agent.stream_run(user_input+KEY_TEMPLATE, remote=True):
            is_final = frame.get("frame_is_final")
            llm_result = frame.get("llm_text", "")
            exec_result = frame.get('exec_result', '') 
            #print(frame)
            history = []
            llm_result = llm_result.split("<|user|>")[0].strip()
            if len(exec_result) != 0:
                [history,task_history]=update_component(exec_result,chatbot,task_history)
                frame_text = " "
                # response = f'{response}\n{frame_text}'
                # chatbot[-1] = (user_input, response)
                # task_history[-1] = (user_input, response)
            else:
                # action_exec_result
                frame_text = llm_result
                response = f'{response}\n{frame_text}'
                chatbot[-1] = (user_input, response)
                task_history[-1] = (user_input, response)
            if history != []:
                 history_image = history
            task_history = task_history[-10:]
            yield chatbot,*copy.deepcopy(output_component),task_history
        try:
            if history_image != []:
                print()
                for item in history_image:
                    chatbot.append(item)
                    yield chatbot,*copy.deepcopy(output_component),task_history           
        except:
            pass

    
        
   
    # ---------- äº‹ä»¶ ---------------------

    stream_predict_input = [user_input, chatbot,task_history]
    stream_predict_output = [chatbot,task_history]

    clean_outputs_start = ['', gr.update(value=[(None, PROMPT_START)])]+[None] * image_num + [''] * image_num
    clean_outputs = ['', gr.update(value=[])]+[None] * image_num + [''] * image_num
    clean_outputs_target = [user_input, chatbot]
    user_input.submit(
        story_agent,
        inputs=stream_predict_input,
        outputs=stream_predict_output,
        show_progress=True)
    user_input.submit(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)
    submitBtn.click(
        story_agent,
        stream_predict_input,
        stream_predict_output,
        show_progress=True
    )
    submitBtn.click(reset_user_input, [], [user_input])
    regenerate_button.click(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)
    regenerate_button.click(
        story_agent,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)

    def clear_session():
        agent.reset()

    clear_session_button.click(fn=clear_session, inputs=[], outputs=[])
    clear_session_button.click(
        fn=lambda: clean_outputs_start, inputs=[], outputs=clean_outputs_target)
    upload_button.upload(add_file, inputs=[chatbot,upload_button,task_history], outputs=[chatbot,task_history],show_progress=True) 
    # chatbot.append((None, PROMPT_START))
demo.title = "Facechian Agent ğŸ"
if __name__ == "__main__":
    multiprocessing.set_start_method('spawn')
    demo.queue(status_update_rate=1).launch()
