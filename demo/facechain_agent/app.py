from __future__ import annotations
import os
import sys
sys.path.append("../../")
#sys.path.append("/home/wsco/wyj2/modelscope-agent-1")
from functools import partial
import json
import shutil
import slugify
import PIL.Image
import gradio as gr
from dotenv import load_dotenv
from modelscope_agent.agent import AgentExecutor
from modelscope_agent.llm import LLMFactory
from modelscope_agent.prompt import MSPromptGenerator, PromptGenerator
from modelscope_agent.retrieve import ToolRetrieval
from gradio_chatbot import ChatBot
#from mock_llm import MockLLM
from help_tool import StyleSearchTool,FaceChainFineTuneTool
import copy
from facechain.train_text_to_image_lora import prepare_dataset,data_process_fn,get_rot
from modelscope.utils.config import Config

PROMPT_START = "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„FacechainAgentï¼Œå¾ˆé«˜å…´ä¸ºä½ æä¾›æœåŠ¡ã€‚é¦–å…ˆï¼Œæˆ‘æƒ³äº†è§£ä½ å¯¹æƒ³è¦åˆ›ä½œçš„å†™çœŸç…§æœ‰ä»€ä¹ˆå¤§æ¦‚çš„æƒ³æ³•ï¼Ÿ"


SYSTEM_PROMPT = """<|system|>: ä½ ç°åœ¨æ‰®æ¼”ä¸€ä¸ªFacechain Agentï¼Œä¸æ–­å’Œç”¨æˆ·æ²Ÿé€šåˆ›ä½œæƒ³æ³•ï¼Œè¯¢é—®ç”¨æˆ·å†™çœŸç…§é£æ ¼ï¼Œæœ€åç”Ÿæˆæœç´¢åˆ°çš„é£æ ¼ç±»å‹è¿”å›ç»™ç”¨æˆ·ã€‚å½“å‰å¯¹è¯å¯ä»¥ä½¿ç”¨çš„æ’ä»¶ä¿¡æ¯å¦‚ä¸‹ï¼Œè¯·è‡ªè¡Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨æ’ä»¶æ¥è§£å†³å½“å‰ç”¨æˆ·é—®é¢˜ã€‚è‹¥éœ€è¦è°ƒç”¨æ’ä»¶ï¼Œåˆ™éœ€è¦å°†æ’ä»¶è°ƒç”¨è¯·æ±‚æŒ‰ç…§jsonæ ¼å¼ç»™å‡ºï¼Œå¿…é¡»åŒ…å«api_nameã€parameterså­—æ®µï¼Œå¹¶åœ¨å…¶å‰åä½¿ç”¨<|startofthink|>å’Œ<|endofthink|>ä½œä¸ºæ ‡å¿—ã€‚ç„¶åä½ éœ€è¦æ ¹æ®æ’ä»¶APIè°ƒç”¨ç»“æœç”Ÿæˆåˆç†çš„ç­”å¤ã€‚
\n<tool_list>\n"""

INSTRUCTION_TEMPLATE = """ã€å¤šè½®å¯¹è¯å†å²ã€‘

Human: ç»™æˆ‘ç”Ÿæˆä¸€ä¸ªå†™çœŸç…§ã€‚

Assistant: å¥½çš„ï¼Œè¯·é—®ä½ æƒ³è¦ä»€ä¹ˆé£æ ¼çš„å†™çœŸç…§ï¼Ÿ

Human: æˆ‘æƒ³è¦èµ›åšæœ‹å…‹é£ã€‚

Assistant: æ˜ç™½äº†ï¼Œæˆ‘å°†ä¸ºä½ æ‰¾åˆ°éœ€è¦çš„é£æ ¼ç±»å‹ã€‚

<|startofthink|>```JSON\n{\n   "api_name": "style_search_tool",\n    "parameters": {\n      "text": "æˆ‘æƒ³è¦èµ›åšæœ‹å…‹é£ã€‚"\n   }\n}\n```<|endofthink|>
æˆ‘ä¸ºä½ æ‰¾åˆ°çš„é£æ ¼ç±»å‹åå­—æ˜¯èµ›åšæœ‹å…‹(Cybernetics punk)ã€‚

ç°åœ¨æˆ‘éœ€è¦ä½ æä¾›1-3å¼ ç…§ç‰‡ï¼Œè¯·ç‚¹å‡»å›¾ç‰‡ä¸Šä¼ æŒ‰é’®ä¸Šä¼ ä½ çš„ç…§ç‰‡ã€‚ä¸Šä¼ å®Œæ¯•ååœ¨å¯¹è¯æ¡†é‡Œå‘Šè¯‰æˆ‘ä½ å·²ç»ä¸Šä¼ å¥½ç…§ç‰‡äº†ã€‚

Human: æˆ‘çš„ç…§ç‰‡ä¸Šä¼ å¥½äº†ã€‚

Assistant: æ”¶åˆ°ï¼Œæˆ‘éœ€è¦10åˆ†é’Ÿè®­ç»ƒå¹¶ç”Ÿæˆï¼Œä½ å¯ä»¥è¿‡10åˆ†é’Ÿå†å›æ¥ç•Œé¢ã€‚

æ­£åœ¨è®­ç»ƒäººç‰©loraä¸­ï¼š<|startofthink|>```JSON\n{\n   "api_name": "facechain_finetune_tool",\n    "parameters": {\n \n   }\n}\n```<|endofthink|>
äººç‰©loraè®­ç»ƒå®Œæˆã€‚æ˜¯å¦æ ¹æ®ä½ åˆšæ‰é€‰çš„èµ›åšæœ‹å…‹é£æ ¼ç”Ÿæˆå†™çœŸç…§ï¼Ÿè¿˜æ˜¯ä½ è¦æ›´æ¢é£æ ¼å—ï¼Ÿ


ã€è§’è‰²æ‰®æ¼”è¦æ±‚ã€‘
ä¸Šé¢å¤šè½®è§’è‰²å¯¹è¯æ˜¯æä¾›çš„åˆ›ä½œä¸€ä¸ªå†™çœŸç…§é£æ ¼è¦å’Œç”¨æˆ·æ²Ÿé€šçš„æ ·ä¾‹ï¼Œè¯·æŒ‰ç…§ä¸Šè¿°çš„è¯¢é—®æ­¥éª¤æ¥å¼•å¯¼ç”¨æˆ·å®Œæˆé£æ ¼çš„ç”Ÿæˆï¼Œæ¯æ¬¡åªå›å¤å¯¹åº”çš„å†…å®¹ï¼Œä¸è¦ç”Ÿæˆå¤šè½®å¯¹è¯ã€‚è®°ä½åªå›å¤ç”¨æˆ·å½“å‰çš„æé—®ï¼Œä¸è¦ç”Ÿæˆå¤šè½®å¯¹è¯ï¼Œå›å¤ä¸è¦åŒ…å«<|user|>åé¢çš„å†…å®¹ã€‚

"""

KEY_TEMPLATE = """ï¼ˆæ³¨æ„ï¼šè¯·å‚ç…§ä¸Šè¿°çš„å¤šè½®å¯¹è¯å†å²æµç¨‹ï¼Œä½†ä¸è¦ç”Ÿæˆå¤šè½®å¯¹è¯ï¼Œå›å¤ä¸è¦åŒ…å«<|user|>çš„å†…å®¹ã€‚ï¼‰"""
#KEY_TEMPLATE = ""



load_dotenv('../../config/.env', override=True)

os.environ['TOOL_CONFIG_FILE'] = '../config/cfg_tool_template.json'
os.environ['MODEL_CONFIG_FILE'] = '../config/cfg_model_template.json'
os.environ['OUTPUT_FILE_DIRECTORY'] = './tmp'
os.environ['MODELSCOPE_API_TOKEN'] = 'c70a097b-50bd-42da-9d45-23bed2121eab'
os.environ['DASHSCOPE_API_KEY'] = 'uwjIui5vzfMXRGfWzdU5hkPdE0FJTFFW95425EAEDCCB11ED9809620D7200B5B8'
os.environ['OPENAI_API_KEY'] = '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'

style_path="/home/wsco/wyj2/facechain/styles/leosamsMoonfilm_filmGrain20"
styles=[]
for filename in os.listdir(style_path):
    file_path = os.path.join(style_path, filename)
    with open(file_path,"r") as f:
        data=json.load(f)
        styles.append(data)


with open(
        os.path.join(os.path.dirname(__file__), 'main.css'), "r",
        encoding="utf-8") as f:
    MAIN_CSS_CODE = f.read()
def upload_file(files,current_files):
    
    file_paths = [file_d['name'] for file_d in current_files] + [file.name for file in files]
    #prepare_dataset([img['name'] for img in instance_images], instance_data_dir=instance_data_dir)
    for i, temp_path in enumerate(file_paths):
        image = PIL.Image.open(temp_path)
        image = image.convert('RGB')
        image = get_rot(image)
        # image = image.resize((new_w, new_h))
        # image = image.resize((new_w, new_h), PIL.Image.ANTIALIAS)
        uuid = 'qw'
        shutil.rmtree(f"./{uuid}", ignore_errors=True)
        base_model_path = 'ly261666/cv_portrait_model'
        revision = 'v2.0'
        sub_path = "film/film"
        output_model_name='person1'
        output_model_name = slugify.slugify(output_model_name)
        # mv user upload data to target dir
        instance_data_dir = os.path.join('./', uuid, 'training_data', base_model_path, output_model_name)
        shutil.rmtree(instance_data_dir, ignore_errors=True)
        if not os.path.exists(instance_data_dir):
            os.makedirs(instance_data_dir)
        out_path = f'{instance_data_dir}/{i:03d}.jpg'
        image.save(out_path, format='JPEG', quality=100)
    data_process_fn(instance_data_dir,True)

    print(file_paths)
        
    return file_paths


with gr.Blocks(css=MAIN_CSS_CODE, theme=gr.themes.Soft()) as demo:
    uuid = gr.Text(label="modelscope_uuid", visible=False)
    with gr.Row():
        gr.HTML(
            """<h1 align="left" style="min-width:200px; margin-top:0;">Facechain Agent</h1>"""
        )
        status_display = gr.HTML(
            "", elem_id="status_display", visible=False, show_label=False)

    with gr.Row(elem_id="container_row").style(equal_height=True):
        
        with gr.Column(min_width=470, scale=6, elem_id='settings'):
            gr.Markdown(""" ğŸŒˆ ä½ å¥½ï¼Œæˆ‘æ˜¯FaceChain Agentï¼Œå¯ä»¥å¸®ä½ ç”Ÿæˆå†™çœŸç…§ç‰‡ã€‚
                        
                        ä»¥ä¸‹æ˜¯å„ç±»é£æ ¼çš„å±•ç¤ºå›¾ï¼Œè¯·æŒ‘é€‰ä½ å–œæ¬¢çš„é£æ ¼å¹¶åœ¨ä¸‹æ–¹çš„èŠå¤©æ¡†é‡Œä¸æˆ‘äº¤æµå§ã€‚""")
            gallery = gr.Gallery(value=[(os.path.join("/home/wsco/wyj2/facechain",item["img"]), item["name"]) for item in styles],
                                            label="é£æ ¼(Style)",
                                            allow_preview=False,
                                            columns=5,
                                            elem_id="gallery",
                                            show_share_button=False,
                                            object_fit="contain"
                                            )
            chatbot = ChatBot(
                elem_id="chatbot",
                elem_classes=["markdown-body"],
                show_label=True,
                height=600)
            with gr.Row(elem_id="chat-bottom-container"):
                with gr.Column(min_width=70, scale=1):
                    clear_session_button = gr.Button(
                        "æ¸…é™¤", elem_id='clear_session_button', default_value=True)
                with gr.Column(scale=12):
                    user_input = gr.Textbox(
                        show_label=False,
                        placeholder="ä¸€èµ·æ¥è‡ªç”±ç”Ÿæˆå†™çœŸç…§å§ï½",
                        elem_id="chat-input").style(container=False)
                with gr.Column(min_width=70, scale=1):
                    submitBtn = gr.Button("å‘é€", variant="primary")
                with gr.Column(min_width=110, scale=1):
                    regenerate_button = gr.Button(
                        "é‡æ–°ç”Ÿæˆ", elem_id='regenerate_button')
                gr.Examples(
                examples=['æˆ‘æƒ³è¦å†™çœŸç…§','æˆ‘æƒ³è¦å‡¤å† éœå¸”é£','æˆ‘çš„ç…§ç‰‡ä¸Šä¼ å¥½äº†'],
                inputs=[user_input],
                label="ç¤ºä¾‹",
                elem_id="chat-examples")
            with gr.Row():
                instance_images = gr.Gallery()
                with gr.Row(min_width=110, scale=1):
                    upload_button = gr.UploadButton("ğŸ“ä¸Šä¼ å›¾ç‰‡", file_types=["image"],file_count="multiple")
                    clear_button = gr.Button("æ¸…ç©ºå›¾ç‰‡(Clear photos)")
            clear_button.click(fn=lambda: [], inputs=None, outputs=instance_images)
            upload_button.upload(upload_file, inputs=[upload_button, instance_images], outputs=instance_images,
                                        queue=False)
            
            #trainer = Trainer()
            # upload_button.click(fn=trainer.run,
            #                     inputs=[instance_images
            #                         ],
            #                     outputs=[output_message])


    # ----------agent å¯¹è±¡åˆå§‹åŒ–--------------------

    tool_cfg_file = os.getenv('TOOL_CONFIG_FILE')
    model_cfg_file = os.getenv('MODEL_CONFIG_FILE')

    tool_cfg = Config.from_file(tool_cfg_file)
    model_cfg = Config.from_file(model_cfg_file)

    model_name = 'openai'
    llm = LLMFactory.build_llm(model_name, model_cfg)
    #llm = MockLLM()

    prompt_generator = MSPromptGenerator(
        system_template=SYSTEM_PROMPT,
        instruction_template=INSTRUCTION_TEMPLATE)

    # model_cfg = {
    #     'modelscope-agent-qwen-7b': {
    #         'model_id': 'damo/MSAgent-Qwen-7B',
    #         'model_revision': 'v1.0.2',
    #         'use_raw_generation_config': True,
    #         'custom_chat': True
    #     }
    # }


    # tools 
    
    model_id = 'damo/nlp_corom_sentence-embedding_chinese-base'
    filepath="/home/wsco/wyj2/modelscope-agent-1/demo/story_agent/style.txt"

    style_search_tool=StyleSearchTool(style_path)
    facechain_finetune_tool=FaceChainFineTuneTool()
    additional_tool_list = {
        style_search_tool.name: style_search_tool,
        facechain_finetune_tool.name:facechain_finetune_tool
    }

    agent = AgentExecutor(
        llm,
        tool_cfg,
        prompt_generator=prompt_generator,
        tool_retrieval=False,
        additional_tool_list=additional_tool_list,
        #knowledge_retrieval=knowledge_retrieval
        )

    agent.set_available_tools(additional_tool_list.keys())

    def story_agent(*inputs):

        global agent
        user_input = inputs[0] 
        chatbot = inputs[1]
        chatbot.append((user_input, None))
        #chatbotd(user_input)
        yield chatbot
        response = ''
        
        for frame in agent.stream_run(user_input+KEY_TEMPLATE, remote=True):
            is_final = frame.get("frame_is_final")
            llm_result = frame.get("llm_text", "")
            exec_result = frame.get('exec_result', '') 
            #print(frame)
            llm_result = llm_result.split("<|user|>")[0].strip()
            if len(exec_result) != 0:
                
                frame_text = " "
            else:
                # action_exec_result
                frame_text = llm_result
            response = f'{response}\n{frame_text}'
            # chatbot[-1] = (user_input, response)
            # yield chatbot
        print("user_input: ",user_input)
        print("response: ",response)
        chatbot[-1] = (user_input, response)
        yield chatbot
    
        
        # chatbot[-1] = (user_input, response)
        # yield chatbot
    
    # ---------- äº‹ä»¶ ---------------------

    stream_predict_input = [user_input, chatbot]
    stream_predict_output = [chatbot]

    clean_outputs_start = ['', gr.update(value=[(None, PROMPT_START)])]
    clean_outputs = ['', gr.update(value=[])] 
    clean_outputs_target = [user_input, chatbot]
    user_input.submit(
        story_agent,
        inputs=stream_predict_input,
        outputs=stream_predict_output,
        show_progress=True)
    user_input.submit(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)

    submitBtn.click(
        story_agent,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)
    submitBtn.click(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)

    regenerate_button.click(
        fn=lambda: clean_outputs, inputs=[], outputs=clean_outputs_target)
    regenerate_button.click(
        story_agent,
        stream_predict_input,
        stream_predict_output,
        show_progress=True)

    def clear_session():
        agent.reset()

    clear_session_button.click(fn=clear_session, inputs=[], outputs=[])
    clear_session_button.click(
        fn=lambda: clean_outputs_start, inputs=[], outputs=clean_outputs_target)
  
    # chatbot.append((None, PROMPT_START))
demo.title = "Facechian Agent ğŸ"
demo.queue(concurrency_count=10, status_update_rate='auto', api_open=False)
demo.launch(show_api=False, share=False)
